{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/3lLobo/basic-probability-programming/blob/master/HW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e4NpTKlJS7v"
      },
      "source": [
        "This week you will implement the EM algorithm. See the assignment for all the details. First we download the data you need. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9QhIS8oIDcZ",
        "outputId": "2d08ee65-369c-4bc1-91af-1e47c7c29da0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget -O geometric_example_data.txt https://raw.githubusercontent.com/probabll/basic-probability-programming/master/weekly_tasks/week5/homework/geometric_example_data.txt\n",
        "!wget -O geometric_data.txt https://raw.githubusercontent.com/probabll/basic-probability-programming/master/weekly_tasks/week5/homework/geometric_data.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-01 11:21:18--  https://raw.githubusercontent.com/probabll/basic-probability-programming/master/weekly_tasks/week5/homework/geometric_example_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8 [text/plain]\n",
            "Saving to: ‘geometric_example_data.txt’\n",
            "\n",
            "geometric_example_d 100%[===================>]       8  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-01 11:21:19 (476 KB/s) - ‘geometric_example_data.txt’ saved [8/8]\n",
            "\n",
            "--2020-12-01 11:21:19--  https://raw.githubusercontent.com/probabll/basic-probability-programming/master/weekly_tasks/week5/homework/geometric_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 253012 (247K) [text/plain]\n",
            "Saving to: ‘geometric_data.txt’\n",
            "\n",
            "geometric_data.txt  100%[===================>] 247.08K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-12-01 11:21:19 (6.37 MB/s) - ‘geometric_data.txt’ saved [253012/253012]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxNO18sWJb8F"
      },
      "source": [
        "Some helper functions that help you working with log-probabilities. You don't need to change this cell. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc73v8NgHuNq"
      },
      "source": [
        "import math\n",
        "\n",
        "def log_add(a, b):\n",
        "    '''Adds to numbers in their logarithmic transformtions.\n",
        "\n",
        "    :param a: The first logarithmically transformed number.\n",
        "    :param b: The second logarithmically transformed number.\n",
        "    :return: The log-sum of the two numbers\n",
        "    '''\n",
        "\n",
        "    if a == -float(\"inf\"):\n",
        "        return b\n",
        "    elif b == -float(\"inf\"):\n",
        "        return a\n",
        "    elif a > b:\n",
        "        return a + math.log1p(math.exp(b-a))\n",
        "    else:\n",
        "        return b + math.log1p(math.exp(a-b))\n",
        "\n",
        "def log_add_list(list_of_numbers):\n",
        "    '''Adds all the logarithmically transformed numbers in a list.\n",
        "\n",
        "    :param list_of_numbers: A list of logarithmically transformed numbers.\n",
        "    '''\n",
        "    result = -float(\"inf\")\n",
        "    for number in list_of_numbers:\n",
        "        result = log_add(number, result)\n",
        "\n",
        "    return result\n",
        "\n",
        "def log_subtract(a , b):\n",
        "    '''Subtracts a logarithmically transformed number b from another such number a.\n",
        "\n",
        "    :param a: The first logarithmically transformed number.\n",
        "    :param b: The second logarithmically transformed number.\n",
        "    :return: The log-difference between a and b\n",
        "    '''\n",
        "\n",
        "    if a == -float(\"inf\"):\n",
        "        return b\n",
        "    elif b == -float(\"inf\"):\n",
        "        return a\n",
        "    elif a > b:\n",
        "        return a + math.log1p(-math.exp(b - a))\n",
        "    else:\n",
        "        return b + math.log1p(-math.exp(a-b))\n",
        "\n",
        "def log_subtract_list(list_of_numbers):\n",
        "    '''Subtracts all the logarithmically transformed numbers in a list from the first one.\n",
        "\n",
        "    :param list_of_numbers: A list of logarithmically transformed numbers.\n",
        "    '''\n",
        "\n",
        "    result = list[0]\n",
        "    for number in list_of_numbers[1:]:\n",
        "        result = log_subtract(result, number)\n",
        "\n",
        "    return result"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Num4NJnJuY2"
      },
      "source": [
        "Edit the parts marked with TODO. See the assignment for all the details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofS8RHelH4sI",
        "outputId": "1639b877-8344-4d71-ac51-fba3f132d3f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import random, sys\n",
        "from math import log, exp, factorial\n",
        "# from logarithms import log_add, log_add_list\n",
        "\n",
        "class GeometricDistribution(object):\n",
        "    '''An implementation of the geometric distribution that whose support includes 0.'''\n",
        "\n",
        "    def __init__(self, param=0.5):\n",
        "        '''Constructor\n",
        "\n",
        "        :param param: The parameter of this geometric distribution\n",
        "        :raises: ValueError if param is not in [0,1]\n",
        "        '''\n",
        "\n",
        "        self.failure = log(1 - param)\n",
        "        self.success = log(param)\n",
        "\n",
        "    def log_prob(self, x):\n",
        "        '''Compute the log-probability of an observation\n",
        "\n",
        "        :param x: The observation\n",
        "        :return: The log-probability of x under this distribution\n",
        "        :raises: ValueError if x is not a non-negative integer\n",
        "        '''\n",
        "\n",
        "        if x%1 != 0 or x < 0:\n",
        "            raise ValueError(\"x is not a non-negative integer\")\n",
        "\n",
        "        return self.success + x*self.failure\n",
        "\n",
        "    def get_param(self):\n",
        "        '''Get the parameter of this distribution\n",
        "\n",
        "        :return: The parameter of this distribution\n",
        "        '''\n",
        "        return exp(self.success)\n",
        "\n",
        "\n",
        "class EM(object):\n",
        "    '''A geometric mixture model that can be trained using EM'''\n",
        "\n",
        "    def __init__(self, num_components = 5, initial_mixture_weights = None, initial_geometric_parameters = None):\n",
        "        '''Constructor\n",
        "\n",
        "        :param num_components: The number of mixture components in this model\n",
        "        :param initial_mixture_weights: A list of initial mixture weights (weights are initialised randomly if no list is provided)\n",
        "        :param initial_geometric_parameters: A list of initial component parameters (initialised randomly if no list is provided)\n",
        "        '''\n",
        "\n",
        "        # total number of mixture components\n",
        "        self.num_components = num_components\n",
        "        # map from components to their mixture_weights (stored as logarithms)\n",
        "        self.mixture_weights = list()\n",
        "        # map from components to their distributions\n",
        "        self.component_distributions = list()\n",
        "        # map from components to their expected number of occurrence (stored as logarithms)\n",
        "        self.expected_component_counts = dict()\n",
        "        # map from components to expected values of observations (stored as logarithms)\n",
        "        self.expected_observation_counts = dict()\n",
        "        self.log_likelihood = 0\n",
        "        self.initialise(initial_mixture_weights, initial_geometric_parameters)\n",
        "\n",
        "    def initialise(self, initial_mixture_weights, initial_geometric_parameters):\n",
        "        '''Initialise the parameters of this model\n",
        "\n",
        "        :param initial_mixture_weights: A list of initial mixture weights (weights are initialised randomly if no list is provided)\n",
        "        :param initial_geometric_parameters: A list of initial component parameters (initialised randomly if no list is provided)\n",
        "        '''\n",
        "\n",
        "        #TODO: the following code performs a random initialization of mixture weights and geometric distributions\n",
        "        #TODO: make sure that the input arguments initial_mixtures_weights and initial_geometric_parameters\n",
        "        #TODO: are used if they are actually provided.\n",
        "\n",
        "        for component in range(self.num_components):\n",
        "            self.mixture_weights.append(random.random())\n",
        "            self.component_distributions.append(GeometricDistribution(random.random()))\n",
        "            # values that are stored as logarithms are initialized as -inf = log(0)\n",
        "            self.expected_component_counts[component] = -float(\"inf\")\n",
        "            self.expected_observation_counts[component] = -float(\"inf\")\n",
        "\n",
        "        # normalise priors\n",
        "        prior_sum = sum(self.mixture_weights)\n",
        "        for component in range(self.num_components):\n",
        "            # normalise and tranform to log-prob\n",
        "            self.mixture_weights[component] = log(self.mixture_weights[component] / prior_sum)\n",
        "\n",
        "    def train(self, data_path, iterations):\n",
        "        '''Train the model on data for a fixed number of iterations. After each iteration of training, the log-likelihood,\n",
        "        mixture weights and component parameters are printed out.\n",
        "\n",
        "        :param data_path: The path to the data file\n",
        "        :param iterations: The number of iterations\n",
        "        '''\n",
        "\n",
        "        for iter in range(iterations):\n",
        "            params = list()\n",
        "            priors = list()\n",
        "            for component in range(self.num_components):\n",
        "                params.append(self.component_distributions[component].get_param())\n",
        "                priors.append(exp(self.mixture_weights[component]))\n",
        "\n",
        "            print(\"\\nIteration {}\".format(iter))\n",
        "            print(\"log-likelihood: {}\".format(self.log_likelihood))\n",
        "            print(\"Component priors: {}\".format(priors))\n",
        "            print(\"Component parameters: {}\".format(params))\n",
        "\n",
        "            # reset log-likelihood\n",
        "            self.log_likelihood = 0\n",
        "\n",
        "            self.em(data_path)\n",
        "\n",
        "\n",
        "\n",
        "    def em(self, data_path):\n",
        "        '''Perform one iteration of EM on the data\n",
        "\n",
        "        :param data_path: The path to the data file\n",
        "        '''\n",
        "        with open(data_path) as data:\n",
        "            for line in data:\n",
        "                for observation in line.split():\n",
        "                    self.e_step(int(observation))\n",
        "\n",
        "        self.m_step()\n",
        "\n",
        "\n",
        "    def e_step(self, observation):\n",
        "        '''Perform the E-step on a single obervation. That is, compute the posterior of mixture components\n",
        "        and add the expected occurrence of each component to the running totals\n",
        "        self.log_likelihood ,\n",
        "        self.expected_component_counts , and\n",
        "        self.expected_observation_counts\n",
        "\n",
        "        :param observation: The observation\n",
        "        '''\n",
        "        # Get estimation\n",
        "        gmm = dict()\n",
        "        log_sum = -float(\"inf\")\n",
        "        for i in range(self.num_components):\n",
        "            log_p = self.mixture_weights[i]+self.component_distributions[i].log_prob(observation)\n",
        "            log_sum = log_add(log_p, log_sum)\n",
        "            gmm[i] = log_p\n",
        "\n",
        "        # Update\n",
        "        for i in range(self.num_components):\n",
        "            nlog_p = gmm[i] - log_sum\n",
        "            self.expected_component_counts[i] = log_add(nlog_p, self.expected_component_counts[i])\n",
        "            if observation:\n",
        "                self.expected_observation_counts[i] = log_add(log(observation) + nlog_p, self.expected_observation_counts[i])\n",
        "        self.log_likelihood += log_sum\n",
        "\n",
        "    def m_step(self):\n",
        "        '''Perform the M-step. This step updates\n",
        "        self.mixture_weights\n",
        "        self.component_distributions\n",
        "        '''\n",
        "        # test if the sum of the summed expected_component_counts is roughly equal to the total amount of observations\n",
        "        sum_obs_counts = log_add_list(self.expected_component_counts.values())\n",
        "        print(\"Sum of expected component counts: {}\".format(exp(sum_obs_counts)))\n",
        "\n",
        "        # Maximisation\n",
        "        for i in range(self.num_components):\n",
        "            self.mixture_weights[i] = self.expected_component_counts[i] - sum_obs_counts\n",
        "            log_trick = exp(self.expected_component_counts[i] - (log_add(self.expected_component_counts[i], self.expected_observation_counts[i])))\n",
        "            self.component_distributions[i] = GeometricDistribution(log_trick)\n",
        "            self.expected_component_counts[i] = -float(\"inf\")\n",
        "            self.expected_observation_counts[i] = -float(\"inf\")\n",
        "\n",
        "def main(data_path, number_mixture_components, initial_mixture_weights=None, initial_geometric_parameters=None):\n",
        "    learner = EM(int(number_mixture_components), initial_mixture_weights, initial_geometric_parameters)\n",
        "    learner.train(data_path, 20)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # TODO: make sure that the first argument points to the data that you have downloaded\n",
        "    # main('geometric_example_data.txt', 2, [0.2, 0.8], [0.2, 0.6])\n",
        "\n",
        "    # TODO: use the following call instead when the small example above is running properly\n",
        "    main('geometric_data.txt', 3)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 0\n",
            "log-likelihood: 0\n",
            "Component priors: [0.4496427118801476, 0.18707969928512924, 0.3632775888347232]\n",
            "Component parameters: [0.4526527795442703, 0.5879069899491672, 0.6851544365154968]\n",
            "Sum of expected component counts: 99999.99999998741\n",
            "\n",
            "Iteration 1\n",
            "log-likelihood: -2547498.0620630085\n",
            "Component priors: [0.6703168917084679, 0.11087709836319967, 0.2188060099283319]\n",
            "Component parameters: [0.016358276450759174, 0.5597919408852334, 0.7504164516085214]\n",
            "Sum of expected component counts: 100000.00000000765\n",
            "\n",
            "Iteration 2\n",
            "log-likelihood: -373539.45985293586\n",
            "Component priors: [0.5121393147672063, 0.1558294590643349, 0.3320312261684594]\n",
            "Component parameters: [0.012550342178740955, 0.6124779302110835, 0.8185075021775281]\n",
            "Sum of expected component counts: 100000.00000000162\n",
            "\n",
            "Iteration 3\n",
            "log-likelihood: -364295.8517000905\n",
            "Component priors: [0.48757062313928234, 0.16627677792126416, 0.3461525989394539]\n",
            "Component parameters: [0.011963438841725562, 0.5640663268612721, 0.8300197156942856]\n",
            "Sum of expected component counts: 100000.0000000098\n",
            "\n",
            "Iteration 4\n",
            "log-likelihood: -363653.90613295644\n",
            "Component priors: [0.4779792713790487, 0.17347086354986724, 0.3485498650710839]\n",
            "Component parameters: [0.01174073034459089, 0.5053364879867012, 0.8451787765524279]\n",
            "Sum of expected component counts: 100000.00000001032\n",
            "\n",
            "Iteration 5\n",
            "log-likelihood: -362994.0331809288\n",
            "Component priors: [0.4686541048800837, 0.1807921151398906, 0.35055377998002557]\n",
            "Component parameters: [0.011526615184075056, 0.4486165446833366, 0.8646077746963989]\n",
            "Sum of expected component counts: 99999.99999999096\n",
            "\n",
            "Iteration 6\n",
            "log-likelihood: -362270.2788860967\n",
            "Component priors: [0.4586854085232077, 0.18812254109974477, 0.3531920503770469]\n",
            "Component parameters: [0.01129903091499608, 0.398556948647829, 0.883509536438289]\n",
            "Sum of expected component counts: 99999.99999999149\n",
            "\n",
            "Iteration 7\n",
            "log-likelihood: -361606.2517870249\n",
            "Component priors: [0.44876824766654705, 0.19492528014596228, 0.35630647218749106]\n",
            "Component parameters: [0.011073816189634822, 0.35749358795813846, 0.8987245447088767]\n",
            "Sum of expected component counts: 99999.99999999131\n",
            "\n",
            "Iteration 8\n",
            "log-likelihood: -361090.38027985545\n",
            "Component priors: [0.43972350262392645, 0.20073694833415845, 0.3595395490419158]\n",
            "Component parameters: [0.010869525160210615, 0.3254102300697148, 0.9095470328731384]\n",
            "Sum of expected component counts: 99999.99999998172\n",
            "\n",
            "Iteration 9\n",
            "log-likelihood: -360734.9796344985\n",
            "Component priors: [0.4320191969480326, 0.2053257216863307, 0.362655081365636]\n",
            "Component parameters: [0.010696461589129859, 0.3009533941502641, 0.916613003293007]\n",
            "Sum of expected component counts: 99999.9999999835\n",
            "\n",
            "Iteration 10\n",
            "log-likelihood: -360507.59351145034\n",
            "Component priors: [0.4257512538661735, 0.20867815925430372, 0.3655705868795228]\n",
            "Component parameters: [0.010556413292114795, 0.2824401412987619, 0.9208613458304976]\n",
            "Sum of expected component counts: 100000.00000000428\n",
            "\n",
            "Iteration 11\n",
            "log-likelihood: -360367.4229077137\n",
            "Component priors: [0.42079285776640607, 0.21092077558150843, 0.36828636665208525]\n",
            "Component parameters: [0.010446185299461156, 0.2683634088616951, 0.9231063829901723]\n",
            "Sum of expected component counts: 100000.0000000128\n",
            "\n",
            "Iteration 12\n",
            "log-likelihood: -360281.6920573809\n",
            "Component priors: [0.4169296033249748, 0.21224242841117202, 0.3708279682638532]\n",
            "Component parameters: [0.010360711865983155, 0.2575356333198482, 0.9239596327714077]\n",
            "Sum of expected component counts: 99999.99999997622\n",
            "\n",
            "Iteration 13\n",
            "log-likelihood: -360228.3578094034\n",
            "Component priors: [0.41393818314107855, 0.21284165018211043, 0.3732201666768109]\n",
            "Component parameters: [0.01029482625168269, 0.24907412483930808, 0.9238611636293217]\n",
            "Sum of expected component counts: 99999.99999998261\n",
            "\n",
            "Iteration 14\n",
            "log-likelihood: -360193.9028240624\n",
            "Component priors: [0.4116212859163697, 0.21289898798049656, 0.3754797261031334]\n",
            "Component parameters: [0.01024401919528396, 0.24234052182310362, 0.9231253883704754]\n",
            "Sum of expected component counts: 99999.99999999131\n",
            "\n",
            "Iteration 15\n",
            "log-likelihood: -360170.4630555731\n",
            "Component priors: [0.4098178986275004, 0.2125663285113526, 0.3776157728611471]\n",
            "Component parameters: [0.01020464291499381, 0.23687876717610615, 0.9219774558153142]\n",
            "Sum of expected component counts: 100000.00000001086\n",
            "\n",
            "Iteration 16\n",
            "log-likelihood: -360153.5964635927\n",
            "Component priors: [0.4084022395547354, 0.21196548358890033, 0.379632276856365]\n",
            "Component parameters: [0.010173866427829694, 0.23236447436830127, 0.9205787207541637]\n",
            "Sum of expected component counts: 100000.00000000001\n",
            "\n",
            "Iteration 17\n",
            "log-likelihood: -360140.82476353063\n",
            "Component priors: [0.4072785139709226, 0.21119096337341334, 0.38153052265566484]\n",
            "Component parameters: [0.010149544478417502, 0.2285668947002224, 0.9190442784281866]\n",
            "Sum of expected component counts: 99999.99999999256\n",
            "\n",
            "Iteration 18\n",
            "log-likelihood: -360130.75944138\n",
            "Component priors: [0.4063748654804596, 0.21031419067981744, 0.38331094383972325]\n",
            "Component parameters: [0.010130074082588652, 0.22532135795025598, 0.9174553125535585]\n",
            "Sum of expected component counts: 99999.99999999042\n",
            "\n",
            "Iteration 19\n",
            "log-likelihood: -360122.60433887155\n",
            "Component priors: [0.40563787991365774, 0.20938785403143326, 0.38497426605490875]\n",
            "Component parameters: [0.010114267176052955, 0.22250963518528077, 0.9158680546310256]\n",
            "Sum of expected component counts: 100000.00000000179\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}